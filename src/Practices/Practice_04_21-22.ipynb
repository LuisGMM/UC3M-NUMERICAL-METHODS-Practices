{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQuoV8dsgXl_"
   },
   "source": [
    "# Differentiation and interpolation\n",
    "\n",
    "1. The second order finite difference formula is \n",
    "\n",
    "$$f''(x)= \\frac{f(x-h)-2f(x)+f(x+h)}{h^2}+O(h^2)$$\n",
    "\n",
    ">- Use it to calculate the second dervative of $e^{-x^2}$ at $x=0$ and $x=1$ using different values of $h$ given by $np.logspace(0,-6,7)$. Plot the error as a function of $h$ (look for the .axis('equal') option). \n",
    "\n",
    ">- Find the finite forward and backward second derivative differences formula (I know you can find it online, but it would be a  good exercise if you try to calculate it yourself) and repeat the previous exercise.\n",
    "\n",
    ">- Calculate the error, the order of convergence (at least be able to tell if it is linear or higher) and explain the results.\n",
    "\n",
    "2. Effect of the errors in the function values when calculating the derivative.\n",
    "\n",
    ">- Code a function that admits a vector that represents the positions in the x axis, and the values of a function at those points as arguments, and returns the approximate values of the derivative at those points using forward finite differences.\n",
    "\n",
    ">- Test it with x = np.linspace(0, 2*np.pi, 100, endpoint=True) and $y=sin(x)$. Compare the result with $cos(x)$.\n",
    "\n",
    ">- Modify the values of $y$ adding to it an array of random numbers of the same size (you may use np.random.normal).\n",
    "\n",
    ">- Now use that modified $y$ to approximate the derivative. What happens?\n",
    "\n",
    ">- Experiment using other finite difference formulas and different separations between nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def dev2(f, x, h) -> float: return ( f(x-h) -2*f(x) + f(x+h) )/ h**2\n",
    "\n",
    "def forward_dev2(f, x, h) -> float: return ( f(x) -2*f(x+h) + f(x+2*h) )/ h**2\n",
    "\n",
    "def backward_dev2(f, x, h) -> float: return ( f(x-2*h) -2*f(x-h) + f(x) )/ h**2\n",
    "\n",
    "\n",
    "def error(f_dev2, approx_dev2, f, x, h): return abs( f_dev2(x) - approx_dev2(f, x, h) )\n",
    "\n",
    "\n",
    "def array_forward_dev2(x, fx): \n",
    "\n",
    "    ans = []\n",
    "\n",
    "    for x, fx in zip(x, fx): ans.append(forward_dev2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    def f(x): return np.e**(- x**2)\n",
    "\n",
    "    def f_dev2(x): return (-2 + 4*x**2)*f(x)\n",
    "\n",
    "    h = np.logspace(0,-6,7)\n",
    "\n",
    "\n",
    "    for method in (dev2, forward_dev2, backward_dev2):\n",
    "\n",
    "        for x in (0,1): \n",
    "            [print(f'Ans: {method(f, x, h_i)},   Error: {error(f_dev2, method, f, x, h_i)} ') for h_i in h]\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        plt.plot(h, error(f_dev2, method, f, 1, h))\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Practice_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
